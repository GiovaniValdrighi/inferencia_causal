{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcomkDYLBOwA",
        "colab_type": "text"
      },
      "source": [
        "# Code for the training process of the Variational AutoEncoder network\n",
        "\n",
        "## 1.Getting acess to the dataset on Google Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzX-LTmO_QfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "7640d5e2-6454-463b-b2d5-cdbe84763e2a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWxlzWs2_XMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgTjdQmYBiz8",
        "colab_type": "text"
      },
      "source": [
        "## 2.Installing Pyro and calling the modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTthbNsI_tdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "outputId": "789b0838-9481-4f74-e95c-57054175b919"
      },
      "source": [
        "!pip3 install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "!pip3 install pyro-ppl"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: torch-0.4.0-{platform}-linux_x86_64.whl is not a valid wheel filename.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.4.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Collecting pyro-ppl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7a/4dc4d39d6db1aae0825a2a2ab60178fc4afb92efd9669be02715d3a16734/pyro_ppl-1.2.1-py3-none-any.whl (486kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 2.8MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/80/5bb262050dd2f30f8819626b7c92339708fe2ed7bd5554c8193b4487b367/tqdm-4.42.1-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.17.5)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/bc/6cdbd1929e32fff62a33592633c2cc0393c7f7739131ccc9c9c4e28ac8dd/pyro_api-0.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (3.1.0)\n",
            "Installing collected packages: tqdm, pyro-api, pyro-ppl\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed pyro-api-0.1.1 pyro-ppl-1.2.1 tqdm-4.42.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSHlaH34_NLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pyro\n",
        "from vae_build import VAE\n",
        "from networks import setup_data_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8946Lj8__NLX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05d511af-4551-496d-b433-30cb195b6928"
      },
      "source": [
        "dataset_zip = np.load('/content/gdrive/My Drive/autoencoder/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz', allow_pickle = True, encoding = 'bytes')\n",
        "print('Keys in the dataset:', dataset_zip.files)\n",
        "imgs = dataset_zip['imgs']\n",
        "latents_values = dataset_zip['latents_values']\n",
        "latents_classes = dataset_zip['latents_classes']\n",
        "latents_sizes = dataset_zip['metadata'][()][b'latents_sizes']\n",
        "latents_names = dataset_zip['metadata'][()][b'latents_names']"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys in the dataset: ['metadata', 'imgs', 'latents_classes', 'latents_values']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAHSXE11Bqwx",
        "colab_type": "text"
      },
      "source": [
        "## 3.The training process\n",
        "In the following training process, we use the Standart variational inference from Pyro. In each testing iteration the state of the model (parameters values of the network) are saved at the Google Drive with the number of epochs in the file name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-B6UxlY_NLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyro.enable_validation(True)\n",
        "pyro.clear_param_store()\n",
        "use_CUDA = False\n",
        "train_loader, test_loader = setup_data_loader(imgs, latents_classes, use_CUDA = use_CUDA)\n",
        "vae = VAE(latents_sizes, latents_names, use_CUDA = use_CUDA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmrvOzoC_NL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#optimizer\n",
        "optimizer = pyro.optim.Adam({\"lr\" : 1.0e-3})\n",
        "\n",
        "#inference algorithm\n",
        "elbo = pyro.infer.Trace_ELBO()\n",
        "svi = pyro.infer.SVI(vae.model, vae.guide, optimizer, elbo)\n",
        "\n",
        "train_elbo = []\n",
        "test_elbo = []\n",
        "num_epochs = 70\n",
        "test_freq = 8\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss = 0.\n",
        "  for (img, label) in train_loader:\n",
        "    if use_CUDA:\n",
        "      img = img.cuda()\n",
        "      label = label.to(img.device)\n",
        "    epoch_loss += svi.step(img, label)\n",
        "  total_epoch_loss_train = epoch_loss/len(train_loader)\n",
        "  train_elbo.append(total_epoch_loss_train)\n",
        "  print(\"epoch: \" + str(epoch) + \" average training loss: \" + str(epoch_loss))\n",
        "\n",
        "  if epoch % test_freq == 0:\n",
        "    test_loss = 0\n",
        "    for (img, label) in test_loader:\n",
        "      if use_CUDA:\n",
        "        img = img.cuda()\n",
        "        label = label.to(img.device)\n",
        "      test_loss += svi.evaluate_loss(img, label)\n",
        "    total_epoch_loss_test  = epoch_loss/len(test_loader)\n",
        "    test_elbo.append(total_epoch_loss_test)\n",
        "    torch.save(vae.state_dict(), '/content/gdrive/My Drive/trained_movel_epoch_'+ str(epoch) + '.save')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}