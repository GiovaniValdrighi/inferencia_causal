{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcomkDYLBOwA",
        "colab_type": "text"
      },
      "source": [
        "# Code for the training process of the Variational AutoEncoder network\n",
        "\n",
        "## 1.Getting acess to the dataset on Google Drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzX-LTmO_QfE",
        "colab_type": "code",
        "outputId": "728aed96-0d6a-4c4d-9e55-a510d9b9b61a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWxlzWs2_XMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgTjdQmYBiz8",
        "colab_type": "text"
      },
      "source": [
        "## 2.Installing Pyro and calling the modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTthbNsI_tdq",
        "colab_type": "code",
        "outputId": "789b0838-9481-4f74-e95c-57054175b919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        }
      },
      "source": [
        "!pip3 install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "!pip3 install pyro-ppl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: torch-0.4.0-{platform}-linux_x86_64.whl is not a valid wheel filename.\u001b[0m\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.4.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Collecting pyro-ppl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/7a/4dc4d39d6db1aae0825a2a2ab60178fc4afb92efd9669be02715d3a16734/pyro_ppl-1.2.1-py3-none-any.whl (486kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 2.8MB/s \n",
            "\u001b[?25hCollecting tqdm>=4.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/80/5bb262050dd2f30f8819626b7c92339708fe2ed7bd5554c8193b4487b367/tqdm-4.42.1-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.17.5)\n",
            "Collecting pyro-api>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c2/bc/6cdbd1929e32fff62a33592633c2cc0393c7f7739131ccc9c9c4e28ac8dd/pyro_api-0.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (3.1.0)\n",
            "Installing collected packages: tqdm, pyro-api, pyro-ppl\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed pyro-api-0.1.1 pyro-ppl-1.2.1 tqdm-4.42.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dohVtgYzr9wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_data_loader(images, classes, batch_size = 128, use_CUDA = False):\n",
        "    '''\n",
        "    Function that receives two arrays, an array of the data images and an array of it latents values\n",
        "    and generate a DataLoader for train and test data.\n",
        "    \n",
        "    Input:\n",
        "    :images: array of size [*, 64, 64] with images data\n",
        "    :classes: array of size [*, 6] with latent variables of the images\n",
        "    \n",
        "    Output:\n",
        "    :train_loader: torch data loader with train data (images and latents)\n",
        "    :test_loader: torch data loader with test data (images and latents)\n",
        "    '''\n",
        "    index = np.random.permutation(images.shape[0])\n",
        "    images = images[index].astype(np.float32)\n",
        "    classes = classes[index].astype(np.float32)\n",
        "    train_df = torch.utils.data.TensorDataset(torch.from_numpy(images[100:].reshape(-1, 4096)), torch.from_numpy(classes[100:]))\n",
        "    test_df = torch.utils.data.TensorDataset(torch.from_numpy(images[:100].reshape(-1, 4096)), torch.from_numpy(classes[:100]))\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': use_CUDA}\n",
        "    train_loader = torch.utils.data.DataLoader(train_df, batch_size, shuffle = False, **kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(test_df, batch_size, shuffle = False, **kwargs)\n",
        "    return train_loader, test_loader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8TDmyc-rvtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import pyro\n",
        "import numpy as np\n",
        "from torch.nn import Module\n",
        "from torch.nn.functional import one_hot\n",
        "from networks import Decoder, Encoder\n",
        "from torch import tensor\n",
        "from pyro.distributions import OneHotCategorical, Normal, Bernoulli, Uniform\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class VAE(Module):\n",
        "    '''\n",
        "    Class that define the posterior distribution q(z|x) as the model \n",
        "    with the decoder and the prior distribution q(x|z) as the guide \n",
        "    using the encoder.\n",
        "    \n",
        "    Inputs:  \n",
        "    :pimg_dim: dimension of image vector\n",
        "    :label_dim: dimension of label vector\n",
        "    :latent_dim: dimension of Z space, output\n",
        "    '''\n",
        "    def __init__(self, img_dim = 4096, label_dim = 114, latent_dim = 200, use_CUDA = False):\n",
        "        super(VAE, self).__init__()\n",
        "        #creating networks\n",
        "        self.encoder = Encoder(img_dim, label_dim, latent_dim)\n",
        "        self.decoder = Decoder(img_dim, label_dim, latent_dim)\n",
        "        self.img_dim = img_dim\n",
        "        self.label_dim = label_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        if use_CUDA:\n",
        "            self.cuda()\n",
        "        self.use_CUDA = use_CUDA\n",
        "  \n",
        "    def label_variable(self, label):\n",
        "        options = {'device': label.device, 'dtype': label.dtype}\n",
        "\n",
        "        shape = pyro.sample(\"label_shape\", \n",
        "            OneHotCategorical(torch.ones(label.shape[0], 3, **options) / (3.0)), \n",
        "            obs = one_hot((label[:, 0] - 1.).to(torch.int64), 3).to(torch.float32))\n",
        "        scale = pyro.sample(\"label_scale\",\n",
        "            Uniform(torch.ones(label.shape[0], 1, **options)*0.5, torch.ones(label.shape[0], 1, **options)*1.0001).to_event(1),\n",
        "            obs = label[:, 1].reshape(label.shape[0], 1))\n",
        "        orien = pyro.sample(\"label_orien\",\n",
        "            Uniform(torch.zeros(label.shape[0], 1, **options), torch.ones(label.shape[0], 1, **options)*2*np.pi).to_event(1),\n",
        "            obs = label[:, 2].reshape(label.shape[0], 1))\n",
        "        posX = pyro.sample(\"label_posX\",\n",
        "            Uniform(torch.zeros(label.shape[0], 1, **options), torch.ones(label.shape[0], 1, **options)*1.0001).to_event(1),\n",
        "            obs = label[:, 3].reshape(label.shape[0], 1))\n",
        "        posY = pyro.sample(\"label_posY\",\n",
        "            Uniform(torch.zeros(label.shape[0], 1, **options), torch.ones(label.shape[0], 1, **options)*1.0001).to_event(1),\n",
        "            obs = label[:, 4].reshape(label.shape[0], 1))\n",
        "\n",
        "        new_label = torch.cat([shape, scale, orien, posX, posY], -1).to(dtype = torch.float32, device = label.device)\n",
        "        return new_label\n",
        "\n",
        "    def model(self, img, label):\n",
        "        pyro.module(\"decoder\", self.decoder)\n",
        "        options = {'device': img.device, 'dtype': img.dtype}\n",
        "        with pyro.plate(\"data\", img.shape[0]):\n",
        "            z_mean = torch.zeros(img.shape[0], self.latent_dim, **options)\n",
        "            z_variance = torch.ones(img.shape[0], self.latent_dim, **options)\n",
        "            z_sample = pyro.sample(\"latent\", Normal(z_mean, z_variance).to_event(1))\n",
        "            image = self.decoder.forward(z_sample, self.label_variable(label))\n",
        "            pyro.sample(\"obs\", Bernoulli(image).to_event(1), obs = img)\n",
        "\n",
        "\n",
        "    def guide(self, img, label):\n",
        "        pyro.module(\"encoder\", self.encoder)\n",
        "        with pyro.plate(\"data\", img.shape[0]):\n",
        "            z_mean, z_variance = self.encoder.forward(img, self.label_variable(label))\n",
        "            pyro.sample(\"latent\", Normal(z_mean, z_variance).to_event(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8946Lj8__NLX",
        "colab_type": "code",
        "outputId": "b3ff8a04-ce76-49d4-f530-01d3807ee63a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_zip = np.load('/content/gdrive/My Drive/autoencoder/dsprites_ndarray_co1sh3sc6or40x32y32_64x64.npz', allow_pickle = True, encoding = 'bytes')\n",
        "print('Keys in the dataset:', dataset_zip.files)\n",
        "imgs = dataset_zip['imgs']\n",
        "latents_values = dataset_zip['latents_values']\n",
        "latents_classes = dataset_zip['latents_classes']\n",
        "latents_sizes = dataset_zip['metadata'][()][b'latents_sizes']\n",
        "latents_names = dataset_zip['metadata'][()][b'latents_names']"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys in the dataset: ['metadata', 'imgs', 'latents_classes', 'latents_values']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAHSXE11Bqwx",
        "colab_type": "text"
      },
      "source": [
        "## 3.The training process\n",
        "In the following training process, we use the Standart variational inference from Pyro. In each testing iteration the state of the model (parameters values of the network) are saved at the Google Drive with the number of epochs in the file name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-B6UxlY_NLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pyro.enable_validation(True)\n",
        "pyro.clear_param_store()\n",
        "use_CUDA = False\n",
        "train_loader, test_loader = setup_data_loader(imgs[:600], latents_values[:, 1:6][:600], use_CUDA = use_CUDA)\n",
        "vae = VAE(label_dim= 7, use_CUDA = use_CUDA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmrvOzoC_NL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "f59520b2-6941-40f0-9ba3-fcd7a6e0c710"
      },
      "source": [
        "#optimizer\n",
        "optimizer = pyro.optim.Adam({\"lr\" : 1.0e-3})\n",
        "\n",
        "#inference algorithm\n",
        "elbo = pyro.infer.Trace_ELBO()\n",
        "svi = pyro.infer.SVI(vae.model, vae.guide, optimizer, elbo)\n",
        "\n",
        "train_elbo = []\n",
        "test_elbo = []\n",
        "num_epochs = 70\n",
        "test_freq = 8\n",
        "for epoch in range(num_epochs):\n",
        "  epoch_loss = 0.\n",
        "  for (img, label) in train_loader:\n",
        "    if use_CUDA:\n",
        "      img = img.cuda()\n",
        "      label = label.to(img.device)\n",
        "    epoch_loss += svi.step(img, label)\n",
        "  total_epoch_loss_train = epoch_loss/len(train_loader)\n",
        "  train_elbo.append(total_epoch_loss_train)\n",
        "  print(\"epoch: \" + str(epoch) + \" average training loss: \" + str(epoch_loss))\n",
        "\n",
        "  if epoch % test_freq == 0:\n",
        "    test_loss = 0\n",
        "    for (img, label) in test_loader:\n",
        "      if use_CUDA:\n",
        "        img = img.cuda()\n",
        "        label = label.to(img.device)\n",
        "      test_loss += svi.evaluate_loss(img, label)\n",
        "    total_epoch_loss_test  = epoch_loss/len(test_loader)\n",
        "    test_elbo.append(total_epoch_loss_test)\n",
        "    torch.save(vae.state_dict(), '/content/gdrive/My Drive/trained_movel_epoch_'+ str(epoch) + '.save')"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyro/util.py:208: UserWarning: Found non-auxiliary vars in guide but not model, consider marking these infer={'is_auxiliary': True}:\n",
            "{'label_posX', 'label_posY', 'label_shape', 'label_scale', 'label_orien'}\n",
            "  guide_vars - aux_vars - model_vars))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 average training loss: 827067.0625\n",
            "epoch: 1 average training loss: 246384.095703125\n",
            "epoch: 2 average training loss: 189836.947265625\n",
            "epoch: 3 average training loss: 174836.4140625\n",
            "epoch: 4 average training loss: 166770.875\n",
            "epoch: 5 average training loss: 162137.564453125\n",
            "epoch: 6 average training loss: 158450.2734375\n",
            "epoch: 7 average training loss: 156589.669921875\n",
            "epoch: 8 average training loss: 155016.4453125\n",
            "epoch: 9 average training loss: 153880.787109375\n",
            "epoch: 10 average training loss: 153052.609375\n",
            "epoch: 11 average training loss: 152473.029296875\n",
            "epoch: 12 average training loss: 151970.373046875\n",
            "epoch: 13 average training loss: 151336.587890625\n",
            "epoch: 14 average training loss: 150737.7734375\n",
            "epoch: 15 average training loss: 150046.619140625\n",
            "epoch: 16 average training loss: 149186.673828125\n",
            "epoch: 17 average training loss: 148301.677734375\n",
            "epoch: 18 average training loss: 146738.9296875\n",
            "epoch: 19 average training loss: 144529.38671875\n",
            "epoch: 20 average training loss: 141083.734375\n",
            "epoch: 21 average training loss: 136714.359375\n",
            "epoch: 22 average training loss: 131691.9453125\n",
            "epoch: 23 average training loss: 124157.390625\n",
            "epoch: 24 average training loss: 116033.873046875\n",
            "epoch: 25 average training loss: 108184.609375\n",
            "epoch: 26 average training loss: 100301.451171875\n",
            "epoch: 27 average training loss: 92450.396484375\n",
            "epoch: 28 average training loss: 85467.7939453125\n",
            "epoch: 29 average training loss: 80017.53515625\n",
            "epoch: 30 average training loss: 75118.291015625\n",
            "epoch: 31 average training loss: 71566.5126953125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-120-efcc1bab5e2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mtotal_epoch_loss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mtrain_elbo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch_loss_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/svi.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# get loss and compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# grab a trace from the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_traces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0mloss_particle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate_loss_particle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_differentiable_loss_particle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_particle\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/elbo.py\u001b[0m in \u001b[0;36m_get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_particles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/trace_elbo.py\u001b[0m in \u001b[0;36m_get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \"\"\"\n\u001b[1;32m     52\u001b[0m         model_trace, guide_trace = get_importance_trace(\n\u001b[0;32m---> 53\u001b[0;31m             \"flat\", self.max_plate_nesting, model, guide, args, kwargs)\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mcheck_if_enumerated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/infer/enum.py\u001b[0m in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mmodel_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_subsample_sites\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mmodel_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mguide_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_score_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_validation_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pyro/poutine/trace_struct.py\u001b[0m in \u001b[0;36mcompute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"log_prob\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                         \u001b[0mlog_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fn\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msite\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/independent.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sum_rightmost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreinterpreted_batch_ndims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/distributions/utils.py\u001b[0m in \u001b[0;36m_sum_rightmost\u001b[0;34m(value, dim)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mrequired_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequired_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Hj0IbtxUPy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}